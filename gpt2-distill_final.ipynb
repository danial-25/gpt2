{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-02-03T12:14:05.098808Z",
     "iopub.status.busy": "2025-02-03T12:14:05.098546Z",
     "iopub.status.idle": "2025-02-03T12:14:57.198781Z",
     "shell.execute_reply": "2025-02-03T12:14:57.198144Z",
     "shell.execute_reply.started": "2025-02-03T12:14:05.098786Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa1ed55b10854b2d8f432184823489a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/234 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04e7ea49fd8d4970ae52a4d4b43b9584",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f7701bbae2c40b9a19db20c7d2257d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1566bc74b83b489385b917805d9aba2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3118fc7b3fb42e398e1ab15b68096bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/68.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3ae448388a04168906a9ad7ecc5e372",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/197 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c619404195fc429ca118d2d5b612bcd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/915 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43cc2e654fb04915a41f471ef5f83666",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.55G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "361de93f30064406b34d6f16e47e8a0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/119 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "teacher_tokenizer = AutoTokenizer.from_pretrained(\"Locutusque/gpt2-large-medical\")\n",
    "teacher_model = AutoModelForCausalLM.from_pretrained(\"Locutusque/gpt2-large-medical\").eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-03T12:15:17.226949Z",
     "iopub.status.busy": "2025-02-03T12:15:17.226594Z",
     "iopub.status.idle": "2025-02-03T12:15:21.158613Z",
     "shell.execute_reply": "2025-02-03T12:15:21.157774Z",
     "shell.execute_reply.started": "2025-02-03T12:15:17.226909Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb82314b18b84dc29a4e6a6123054572",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14b183361cd6444aa90b52f9d7fe21d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcf512f393874980a7feff3f5d642da8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29d6d8753b32422e9030b315ee895d05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eca3f2ea4ce4df09245ed2a693aeed1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37e8f3f3001d44bca8b73e7b76874fa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4da84ff2f4994600865b7a93258692d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "student_tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2\")\n",
    "student_model = AutoModelForCausalLM.from_pretrained(\"openai-community/gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T13:57:16.668043Z",
     "iopub.status.busy": "2025-01-28T13:57:16.667738Z",
     "iopub.status.idle": "2025-01-28T13:57:16.672687Z",
     "shell.execute_reply": "2025-01-28T13:57:16.671892Z",
     "shell.execute_reply.started": "2025-01-28T13:57:16.668021Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50257 50257\n"
     ]
    }
   ],
   "source": [
    "print(teacher_tokenizer.vocab_size, student_tokenizer.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T13:57:16.674182Z",
     "iopub.status.busy": "2025-01-28T13:57:16.673948Z",
     "iopub.status.idle": "2025-01-28T13:57:16.694235Z",
     "shell.execute_reply": "2025-01-28T13:57:16.693240Z",
     "shell.execute_reply.started": "2025-01-28T13:57:16.674132Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50260, 1280)\n",
       "    (wpe): Embedding(1024, 1280)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-35): 36 x GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2SdpaAttention(\n",
       "          (c_attn): Conv1D(nf=3840, nx=1280)\n",
       "          (c_proj): Conv1D(nf=1280, nx=1280)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=5120, nx=1280)\n",
       "          (c_proj): Conv1D(nf=1280, nx=5120)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1280, out_features=50260, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T15:00:12.640997Z",
     "iopub.status.busy": "2025-01-28T15:00:12.640659Z",
     "iopub.status.idle": "2025-01-28T15:00:12.647640Z",
     "shell.execute_reply": "2025-01-28T15:00:12.646624Z",
     "shell.execute_reply.started": "2025-01-28T15:00:12.640968Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): GPT2LMHeadModel(\n",
       "    (transformer): GPT2Model(\n",
       "      (wte): Embedding(50257, 768)\n",
       "      (wpe): Embedding(1024, 768)\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "      (h): ModuleList(\n",
       "        (0-11): 12 x GPT2Block(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): GPT2SdpaAttention(\n",
       "            (c_attn): Conv1D(nf=2304, nx=768)\n",
       "            (c_proj): Conv1D(nf=768, nx=768)\n",
       "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): GPT2MLP(\n",
       "            (c_fc): Conv1D(nf=3072, nx=768)\n",
       "            (c_proj): Conv1D(nf=768, nx=3072)\n",
       "            (act): NewGELUActivation()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-03T12:20:12.896331Z",
     "iopub.status.busy": "2025-02-03T12:20:12.896017Z",
     "iopub.status.idle": "2025-02-03T12:20:13.174144Z",
     "shell.execute_reply": "2025-02-03T12:20:13.173388Z",
     "shell.execute_reply.started": "2025-02-03T12:20:12.896308Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(50260, 768)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_tokenizer.add_tokens([\"<|startoftext|>\", \"<|prompt|>\", \"<|completion|>\"])\n",
    "student_model.resize_token_embeddings(len(student_tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T15:00:41.522887Z",
     "iopub.status.busy": "2025-01-28T15:00:41.522580Z",
     "iopub.status.idle": "2025-01-28T15:00:41.528980Z",
     "shell.execute_reply": "2025-01-28T15:00:41.528069Z",
     "shell.execute_reply.started": "2025-01-28T15:00:41.522863Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50260, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2SdpaAttention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50260, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-03T12:15:29.449962Z",
     "iopub.status.busy": "2025-02-03T12:15:29.449462Z",
     "iopub.status.idle": "2025-02-03T12:15:29.890406Z",
     "shell.execute_reply": "2025-02-03T12:15:29.889447Z",
     "shell.execute_reply.started": "2025-02-03T12:15:29.449918Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"hf://datasets/BI55/MedText/medtext_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-03T12:15:32.941833Z",
     "iopub.status.busy": "2025-02-03T12:15:32.941541Z",
     "iopub.status.idle": "2025-02-03T12:15:32.964739Z",
     "shell.execute_reply": "2025-02-03T12:15:32.963825Z",
     "shell.execute_reply.started": "2025-02-03T12:15:32.941810Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prompt</th>\n",
       "      <th>Completion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A 50-year-old male presents with a history of ...</td>\n",
       "      <td>This patient's history of recurrent kidney sto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A 7-year-old boy presents with a fever, headac...</td>\n",
       "      <td>This child's symptoms of a red, bulging tympan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A 35-year-old woman presents with a persistent...</td>\n",
       "      <td>While the symptoms might initially suggest ast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A 50-year-old male presents with severe abdomi...</td>\n",
       "      <td>The patient's symptoms suggest an incarcerated...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A newborn baby presents with eye redness and a...</td>\n",
       "      <td>The infant's symptoms suggest neonatal conjunc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1407</th>\n",
       "      <td>A 55-year-old male with a history of chronic o...</td>\n",
       "      <td>While this patient's symptoms could be due to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1408</th>\n",
       "      <td>Can diet and lifestyle changes help manage vit...</td>\n",
       "      <td>While there is no specific diet or lifestyle m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1409</th>\n",
       "      <td>A 50-year-old female presents with right shoul...</td>\n",
       "      <td>This patient's shoulder and arm pain following...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1410</th>\n",
       "      <td>A 60-year-old female with high cholesterol lev...</td>\n",
       "      <td>In addition to a diet low in saturated fats an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1411</th>\n",
       "      <td>What are the main subtypes of vitiligo and how...</td>\n",
       "      <td>The main subtypes of vitiligo are non-segmenta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1412 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Prompt  \\\n",
       "0     A 50-year-old male presents with a history of ...   \n",
       "1     A 7-year-old boy presents with a fever, headac...   \n",
       "2     A 35-year-old woman presents with a persistent...   \n",
       "3     A 50-year-old male presents with severe abdomi...   \n",
       "4     A newborn baby presents with eye redness and a...   \n",
       "...                                                 ...   \n",
       "1407  A 55-year-old male with a history of chronic o...   \n",
       "1408  Can diet and lifestyle changes help manage vit...   \n",
       "1409  A 50-year-old female presents with right shoul...   \n",
       "1410  A 60-year-old female with high cholesterol lev...   \n",
       "1411  What are the main subtypes of vitiligo and how...   \n",
       "\n",
       "                                             Completion  \n",
       "0     This patient's history of recurrent kidney sto...  \n",
       "1     This child's symptoms of a red, bulging tympan...  \n",
       "2     While the symptoms might initially suggest ast...  \n",
       "3     The patient's symptoms suggest an incarcerated...  \n",
       "4     The infant's symptoms suggest neonatal conjunc...  \n",
       "...                                                 ...  \n",
       "1407  While this patient's symptoms could be due to ...  \n",
       "1408  While there is no specific diet or lifestyle m...  \n",
       "1409  This patient's shoulder and arm pain following...  \n",
       "1410  In addition to a diet low in saturated fats an...  \n",
       "1411  The main subtypes of vitiligo are non-segmenta...  \n",
       "\n",
       "[1412 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T13:57:18.007747Z",
     "iopub.status.busy": "2025-01-28T13:57:18.007496Z",
     "iopub.status.idle": "2025-01-28T13:57:18.016372Z",
     "shell.execute_reply": "2025-01-28T13:57:18.015626Z",
     "shell.execute_reply.started": "2025-01-28T13:57:18.007726Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T07:24:34.036384Z",
     "iopub.status.busy": "2025-01-30T07:24:34.036046Z",
     "iopub.status.idle": "2025-01-30T07:24:34.042408Z",
     "shell.execute_reply": "2025-01-30T07:24:34.041492Z",
     "shell.execute_reply.started": "2025-01-30T07:24:34.036354Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2SdpaAttention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-03T12:15:47.252647Z",
     "iopub.status.busy": "2025-02-03T12:15:47.252352Z",
     "iopub.status.idle": "2025-02-03T12:15:48.126650Z",
     "shell.execute_reply": "2025-02-03T12:15:48.125774Z",
     "shell.execute_reply.started": "2025-02-03T12:15:47.252625Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31553dd8f47742d59ae4bc46039aa1ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1412 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset = Dataset.from_pandas(df[['Prompt', 'Completion']])\n",
    "\n",
    "\n",
    "def format_text(row):\n",
    "    return f\"<|prompt|>{row['Prompt']} <|completion|>{row['Completion']}{student_tokenizer.eos_token}\"\n",
    "\n",
    "dataset = dataset.map(lambda x: {'text': format_text(x)})\n",
    "\n",
    "texts = dataset['text']\n",
    "\n",
    "# Split dataset into train, validation, and test\n",
    "train_texts, val_texts = train_test_split(texts, test_size=0.1)  # 10% for validation\n",
    "val_texts, test_texts = train_test_split(val_texts, test_size=0.5)  # Split remaining validation into test (50%)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-03T12:15:54.695331Z",
     "iopub.status.busy": "2025-02-03T12:15:54.695036Z",
     "iopub.status.idle": "2025-02-03T12:15:54.700312Z",
     "shell.execute_reply": "2025-02-03T12:15:54.699422Z",
     "shell.execute_reply.started": "2025-02-03T12:15:54.695308Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<|prompt|>A 30-year-old female presents with excessive thirst and frequent urination. Her blood tests show a sodium level of 145 mEq/L, glucose of 380 mg/dL, and HbA1c of 9.5%. What could be the potential causes, and what are the next steps? <|completion|>This patient's symptoms and lab results suggest poorly controlled diabetes mellitus, most likely type 1 given her age and symptoms. The next step would be to start insulin therapy and provide diabetes education, including the importance of regular monitoring of blood glucose levels, diet and lifestyle modifications.<|endoftext|>\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_texts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-03T12:15:57.379126Z",
     "iopub.status.busy": "2025-02-03T12:15:57.378753Z",
     "iopub.status.idle": "2025-02-03T12:15:57.384483Z",
     "shell.execute_reply": "2025-02-03T12:15:57.383606Z",
     "shell.execute_reply.started": "2025-02-03T12:15:57.379097Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class GPTDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, texts, tokenizer, max_length=1024):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.texts = texts\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        encodings = self.tokenizer(\n",
    "            text,\n",
    "            max_length=self.max_length,\n",
    "            truncation=True, padding=False,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        x = encodings.input_ids.squeeze(0)\n",
    "        return x[:-1], x[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T13:57:18.418744Z",
     "iopub.status.busy": "2025-01-28T13:57:18.418419Z",
     "iopub.status.idle": "2025-01-28T13:57:18.439596Z",
     "shell.execute_reply": "2025-01-28T13:57:18.438782Z",
     "shell.execute_reply.started": "2025-01-28T13:57:18.418713Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50260, 1280)\n",
       "    (wpe): Embedding(1024, 1280)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-35): 36 x GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2SdpaAttention(\n",
       "          (c_attn): Conv1D(nf=3840, nx=1280)\n",
       "          (c_proj): Conv1D(nf=1280, nx=1280)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=5120, nx=1280)\n",
       "          (c_proj): Conv1D(nf=1280, nx=5120)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1280, out_features=50260, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T13:57:18.440526Z",
     "iopub.status.busy": "2025-01-28T13:57:18.440333Z",
     "iopub.status.idle": "2025-01-28T13:57:18.685763Z",
     "shell.execute_reply": "2025-01-28T13:57:18.684662Z",
     "shell.execute_reply.started": "2025-01-28T13:57:18.440508Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!export CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T08:55:12.357664Z",
     "iopub.status.busy": "2025-01-29T08:55:12.357310Z",
     "iopub.status.idle": "2025-01-29T09:56:57.771412Z",
     "shell.execute_reply": "2025-01-29T09:56:57.770157Z",
     "shell.execute_reply.started": "2025-01-29T08:55:12.357632Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-6788c62a7bc6>:192: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location='cuda:0')\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 100, Loss: 113.8351, Time per step: 1.46s\n",
      "Epoch 1/20, Validation Loss: 97.1170\n",
      "Validation loss improved! Saving model...\n",
      "Step 200, Loss: 95.8799, Time per step: 1.60s\n",
      "Epoch 2/20, Validation Loss: 87.8505\n",
      "Validation loss improved! Saving model...\n",
      "Step 300, Loss: 86.3300, Time per step: 1.60s\n",
      "Epoch 3/20, Validation Loss: 81.5681\n",
      "Validation loss improved! Saving model...\n",
      "Step 400, Loss: 86.2340, Time per step: 1.61s\n",
      "Epoch 4/20, Validation Loss: 77.0286\n",
      "Validation loss improved! Saving model...\n",
      "Step 500, Loss: 77.7315, Time per step: 1.60s\n",
      "Epoch 5/20, Validation Loss: 73.4887\n",
      "Validation loss improved! Saving model...\n",
      "Step 600, Loss: 70.6456, Time per step: 1.60s\n",
      "Epoch 6/20, Validation Loss: 70.5648\n",
      "Validation loss improved! Saving model...\n",
      "Step 700, Loss: 76.0063, Time per step: 1.60s\n",
      "Step 800, Loss: 64.9291, Time per step: 1.51s\n",
      "Epoch 7/20, Validation Loss: 68.2140\n",
      "Validation loss improved! Saving model...\n",
      "Step 900, Loss: 71.7493, Time per step: 1.61s\n",
      "Epoch 8/20, Validation Loss: 66.2517\n",
      "Validation loss improved! Saving model...\n",
      "Step 1000, Loss: 65.0194, Time per step: 1.61s\n",
      "Epoch 9/20, Validation Loss: 64.5034\n",
      "Validation loss improved! Saving model...\n",
      "Step 1100, Loss: 59.1273, Time per step: 1.60s\n",
      "Epoch 10/20, Validation Loss: 62.8544\n",
      "Validation loss improved! Saving model...\n",
      "Step 1200, Loss: 55.7428, Time per step: 1.60s\n",
      "Epoch 11/20, Validation Loss: 60.7399\n",
      "Validation loss improved! Saving model...\n",
      "Step 1300, Loss: 57.7214, Time per step: 1.61s\n",
      "Epoch 12/20, Validation Loss: 57.6831\n",
      "Validation loss improved! Saving model...\n",
      "Step 1400, Loss: 51.3218, Time per step: 1.60s\n",
      "Step 1500, Loss: 45.9428, Time per step: 1.52s\n",
      "Epoch 13/20, Validation Loss: 52.7293\n",
      "Validation loss improved! Saving model...\n",
      "Step 1600, Loss: 39.5160, Time per step: 1.60s\n",
      "Epoch 14/20, Validation Loss: 46.3213\n",
      "Validation loss improved! Saving model...\n",
      "Step 1700, Loss: 29.8134, Time per step: 1.61s\n",
      "Epoch 15/20, Validation Loss: 38.0779\n",
      "Validation loss improved! Saving model...\n",
      "Step 1800, Loss: 27.9357, Time per step: 1.61s\n",
      "Epoch 16/20, Validation Loss: 37.7867\n",
      "Validation loss improved! Saving model...\n",
      "Step 1900, Loss: 33.4702, Time per step: 1.62s\n",
      "Epoch 17/20, Validation Loss: 37.2973\n",
      "Validation loss improved! Saving model...\n",
      "Step 2000, Loss: 29.6089, Time per step: 1.59s\n",
      "Epoch 18/20, Validation Loss: 36.9415\n",
      "Validation loss improved! Saving model...\n",
      "Step 2100, Loss: 28.1779, Time per step: 1.60s\n",
      "Step 2200, Loss: 28.9242, Time per step: 1.52s\n",
      "Epoch 19/20, Validation Loss: 36.7681\n",
      "Validation loss improved! Saving model...\n",
      "Step 2300, Loss: 26.8274, Time per step: 1.61s\n",
      "Epoch 20/20, Validation Loss: 36.3349\n",
      "Validation loss improved! Saving model...\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import time\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def collate_fn(batch):\n",
    "    inputs, targets = zip(*batch)\n",
    "    input_ids = torch.nn.utils.rnn.pad_sequence(inputs, batch_first=True, padding_value=50256)  # GPT-2 padding token\n",
    "    target_ids = torch.nn.utils.rnn.pad_sequence(targets, batch_first=True, padding_value=50256)\n",
    "    return input_ids, target_ids\n",
    "\n",
    "\n",
    "class GPTDistillTrainer:\n",
    "    def __init__(self, student_model, teacher_model, train_dataset, val_dataset, device_student, device_teacher, config, save_dir):\n",
    "        self.student_model = student_model\n",
    "        self.teacher_model = teacher_model\n",
    "        self.train_dataset = train_dataset\n",
    "        self.val_dataset = val_dataset\n",
    "        self.device_student = device_student\n",
    "        self.device_teacher = device_teacher\n",
    "        self.config = config\n",
    "        self.save_dir = save_dir  \n",
    "\n",
    "        self.optimizer = torch.optim.AdamW(\n",
    "            self.student_model.parameters(),\n",
    "            lr=config['lr'],\n",
    "            weight_decay=config['weight_decay']\n",
    "        )\n",
    "\n",
    "        self.best_val_loss = float('inf') \n",
    "        self.best_model_path = os.path.join(self.save_dir, \"best_model.pth\")\n",
    "\n",
    "        self.student_model=nn.DataParallel(self.student_model)\n",
    "        self.teacher_model=nn.DataParallel(self.teacher_model)\n",
    "        \n",
    "        self.student_model.to(self.device_student)\n",
    "        self.teacher_model.to(self.device_teacher)\n",
    "\n",
    "    def evaluate(self, val_loader, epoch):\n",
    "        self.student_model.eval()\n",
    "        self.teacher_model.eval()  # Ensure teacher is also in eval mode\n",
    "        total_loss = 0\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                batch = [b.to(self.device_student) for b in batch]\n",
    "                input_ids, target_ids = batch\n",
    "                student_outputs = self.student_model(input_ids, labels=target_ids)\n",
    "                student_logits, student_loss = student_outputs.logits, student_outputs.loss\n",
    "                input_ids_teacher = input_ids.to(self.device_teacher)\n",
    "                teacher_outputs = self.teacher_model(input_ids_teacher, labels=target_ids.to(self.device_teacher))\n",
    "                teacher_logits = teacher_outputs.logits.to(self.device_student)\n",
    "    \n",
    "                # Compute full distillation loss\n",
    "                loss = self.distillation_loss(student_logits, teacher_logits, target_ids, epoch)\n",
    "                total_loss += loss.item()\n",
    "    \n",
    "        avg_loss = total_loss / len(val_loader)\n",
    "        return avg_loss\n",
    "\n",
    "\n",
    "    def distillation_loss(self, student_logits, teacher_logits, target_ids, epoch, temperature=2.0, alpha=0.35):\n",
    "        temperature = max(1.5, 5.0 * (1 - epoch / self.config['epochs'])) \n",
    "        soft_labels = torch.nn.functional.softmax(teacher_logits / temperature, dim=-1)\n",
    "        student_log_probs = torch.nn.functional.log_softmax(student_logits / temperature, dim=-1)\n",
    "        distill_loss = torch.nn.functional.kl_div(\n",
    "            student_log_probs, soft_labels, reduction='batchmean'\n",
    "        ) * (temperature ** 2)\n",
    "        \n",
    "        ce_loss = torch.nn.functional.cross_entropy(\n",
    "            student_logits.view(-1, student_logits.size(-1)), \n",
    "            target_ids.view(-1), \n",
    "            ignore_index=50256\n",
    "        )\n",
    "        \n",
    "        return alpha * ce_loss + (1 - alpha) * distill_loss\n",
    "\n",
    "    def train(self):\n",
    "        train_loader = DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.config['batch_size'],\n",
    "            shuffle=True,\n",
    "            collate_fn=collate_fn,\n",
    "            num_workers=self.config['num_workers'],\n",
    "            pin_memory=True\n",
    "        )\n",
    "\n",
    "        val_loader = DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=self.config['batch_size'],\n",
    "            shuffle=False,\n",
    "            collate_fn=collate_fn,\n",
    "            num_workers=self.config['num_workers'],\n",
    "            pin_memory=True\n",
    "        )\n",
    "\n",
    "        # Training loop\n",
    "        global_step = 0\n",
    "        start_time = time.time()\n",
    "\n",
    "        for epoch in range(self.config['epochs']):\n",
    "            # Training step\n",
    "            for step, batch in enumerate(train_loader):\n",
    "                batch = [b.to(self.device_student) for b in batch]\n",
    "                input_ids, target_ids = batch\n",
    "\n",
    "                student_outputs = self.student_model(input_ids, labels=target_ids)\n",
    "                student_logits, student_loss = student_outputs.logits, student_outputs.loss\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    input_ids_teacher = input_ids.to(self.device_teacher) \n",
    "                    teacher_outputs = self.teacher_model(input_ids_teacher, labels=target_ids.to(self.device_teacher))\n",
    "                    teacher_logits = teacher_outputs.logits\n",
    "\n",
    "                teacher_logits = teacher_logits.to(self.device_student)\n",
    "                loss = self.distillation_loss(student_logits, teacher_logits, target_ids, epoch)\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(self.student_model.parameters(), self.config['grad_norm_clip'])\n",
    "                self.optimizer.step()\n",
    "\n",
    "\n",
    "                global_step += 1\n",
    "                if global_step % self.config['log_interval'] == 0:\n",
    "                    elapsed = time.time() - start_time\n",
    "                    print(f\"Step {global_step}, Loss: {loss.item():.4f}, Time per step: {elapsed / self.config['log_interval']:.2f}s\")\n",
    "                    start_time = time.time()\n",
    "\n",
    "            # Validation step after each epoch\n",
    "            val_loss = self.evaluate(val_loader, epoch)\n",
    "            print(f\"Epoch {epoch+1}/{self.config['epochs']}, Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "            # Save the model if the validation loss is the best we've seen\n",
    "            if val_loss < self.best_val_loss:\n",
    "                self.best_val_loss = val_loss\n",
    "                print(f\"Validation loss improved! Saving model...\")\n",
    "                torch.save(self.student_model.state_dict(), self.best_model_path)\n",
    "\n",
    "# Configuration dictionary\n",
    "config = {\n",
    "    'lr': 3e-5,\n",
    "    'weight_decay': 0.1,\n",
    "    'batch_size': 11,\n",
    "    'num_workers': 4,\n",
    "    'grad_norm_clip': 1.0,\n",
    "    'epochs': 20,\n",
    "    'log_interval': 100,\n",
    "    'temperature': 3.0,  # Added temperature\n",
    "    'alpha': 0.5,  # CE vs distill weight\n",
    "    'warmup_steps': 500,  # For scheduler\n",
    "}\n",
    "\n",
    "# Define your save directory\n",
    "save_dir = './saved_models'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Assuming train_texts and val_texts are your dataset\n",
    "train_dataset = GPTDataset(train_texts, teacher_tokenizer)\n",
    "val_dataset = GPTDataset(val_texts, teacher_tokenizer)\n",
    "\n",
    "\n",
    "device_student = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device_teacher = torch.device(\"cuda\" if torch.cuda.device_count() > 1 else \"cpu\")\n",
    "\n",
    "model_path = '/kaggle/input/gpt2-s/pytorch/default/1/best_model(7).pth'\n",
    "\n",
    "checkpoint = torch.load(model_path, map_location='cuda:0')\n",
    "\n",
    "\n",
    "\n",
    "from collections import OrderedDict\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in checkpoint.items():\n",
    "    name = k[7:]  # remove 'module.' from key names\n",
    "    new_state_dict[name] = v\n",
    "\n",
    "student_model.load_state_dict(new_state_dict)\n",
    "\n",
    "trainer = GPTDistillTrainer(student_model, teacher_model, train_dataset, val_dataset, device_student, device_teacher, config, save_dir)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-03T12:17:03.901350Z",
     "iopub.status.busy": "2025-02-03T12:17:03.901052Z",
     "iopub.status.idle": "2025-02-03T12:17:08.733017Z",
     "shell.execute_reply": "2025-02-03T12:17:08.732126Z",
     "shell.execute_reply.started": "2025-02-03T12:17:03.901328Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: <|prompt|> A 7-year-old boy presents with a fever, headache, and severe earache. He also complains of dizziness and a spinning sensation. Examination reveals a red, bulging tympanic membrane. What are the differential diagnoses, and what should be done next?<|completion|>\n",
      "\n",
      "True Answer: This child's symptoms of a red, bulging tympanic membrane with systemic symptoms such as fever and headache, and the additional symptoms of dizziness and a spinning sensation, raise concern for complications of acute otitis media. The differential diagnosis could include labyrinthitis or possibly even mastoiditis. Urgent evaluation, including further imaging studies such as a CT or MRI scan, may be necessary. This child likely requires admission for intravenous antibiotics and possibly surgical intervention if mastoiditis is confirmed.\n",
      "\n",
      "Generated Answer: <|prompt|> A 7-year-old boy presents with a fever, headache, and severe earache. He also complains of dizziness and a spinning sensation. Examination reveals a red, bulging tympanic membrane. What are the differential diagnoses, and what should be done next?<|completion|> A diagnosis of a malady. This condition can be caused by a medical condition and/or a medical disorder. A diagnosis is a diagnostic or control diagnosis. The diagnosis is based on the medical condition of the patient and is not a medical condition either. A medical condition means a condition that is not consistent with, or is of a clinical and/or clinical significance. A medical condition is a medical condition when it is caused by an impairment in or disability of the body or a disease or injury to the body. A medical condition is a condition that can be caused by: (i) any medical abnormality; (ii) a deficiency in the body or a disease or injury to the body; or (iii) a deficiency in the brain or brain function. A medical condition is a condition that is not consistent with, or is of a clinical and/or clinical significance. A medical condition is a condition that can be caused by: (i) any medical abnormality; (ii) a deficiency in the body or a disease or injury to the body; or (iii) a deficiency in the brain or brain function. A medical condition is a condition that is not consistent with, or is of a clinical and/or clinical significance. A medical condition is a condition that can be caused by: (i) any medical abnormality; (ii) a deficiency in the body or a disease or injury to the body; or (iii) a deficiency in the brain or brain function. A medical condition is a condition that can be caused by: (i) any medical abnormality; (ii) a deficiency in the body or a disease or injury to the body; or (iii) a deficiency in the brain or brain function. A medical condition is a condition that can be caused by: (i) any medical abnormality; (ii) a deficiency in the body or a disease or injury to the body; or (iii) a deficiency in the brain or brain function. A medical condition is a condition that can be caused by: (i) any medical abnormality; (ii) a deficiency in the body or a disease or injury to the body; or (iii) a deficiency in the brain or brain function. A medical condition is a condition that can be caused by: (i) any medical abnormality; (ii) a deficiency in the body or a disease or injury to the body; or (iii) a deficiency in the brain or brain function. A medical condition is a condition that can be caused by: (\n",
      "\n",
      "Full Generated Text: <|prompt|> A 7-year-old boy presents with a fever, headache, and severe earache. He also complains of dizziness and a spinning sensation. Examination reveals a red, bulging tympanic membrane. What are the differential diagnoses, and what should be done next?<|completion|> A diagnosis of a malady. This condition can be caused by a medical condition and/or a medical disorder. A diagnosis is a diagnostic or control diagnosis. The diagnosis is based on the medical condition of the patient and is not a medical condition either. A medical condition means a condition that is not consistent with, or is of a clinical and/or clinical significance. A medical condition is a medical condition when it is caused by an impairment in or disability of the body or a disease or injury to the body. A medical condition is a condition that can be caused by: (i) any medical abnormality; (ii) a deficiency in the body or a disease or injury to the body; or (iii) a deficiency in the brain or brain function. A medical condition is a condition that is not consistent with, or is of a clinical and/or clinical significance. A medical condition is a condition that can be caused by: (i) any medical abnormality; (ii) a deficiency in the body or a disease or injury to the body; or (iii) a deficiency in the brain or brain function. A medical condition is a condition that is not consistent with, or is of a clinical and/or clinical significance. A medical condition is a condition that can be caused by: (i) any medical abnormality; (ii) a deficiency in the body or a disease or injury to the body; or (iii) a deficiency in the brain or brain function. A medical condition is a condition that can be caused by: (i) any medical abnormality; (ii) a deficiency in the body or a disease or injury to the body; or (iii) a deficiency in the brain or brain function. A medical condition is a condition that can be caused by: (i) any medical abnormality; (ii) a deficiency in the body or a disease or injury to the body; or (iii) a deficiency in the brain or brain function. A medical condition is a condition that can be caused by: (i) any medical abnormality; (ii) a deficiency in the body or a disease or injury to the body; or (iii) a deficiency in the brain or brain function. A medical condition is a condition that can be caused by: (i) any medical abnormality; (ii) a deficiency in the body or a disease or injury to the body; or (iii) a deficiency in the brain or brain function. A medical condition is a condition that can be caused by: (\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch.nn as nn\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "student_tokenizer.pad_token = student_tokenizer.eos_token\n",
    "prompt = f\"<|prompt|> {df['Prompt'].iloc[1]}<|completion|>\"\n",
    "true_answer = df[\"Completion\"].iloc[1]\n",
    "inputs = student_tokenizer(prompt, return_tensors=\"pt\", add_special_tokens=True).to(device)\n",
    "student_model.to(device)\n",
    "with torch.no_grad():\n",
    "    output_ids = student_model.generate(\n",
    "        inputs.input_ids,\n",
    "        max_new_tokens=512,  # Generate up to 512 new tokens (better than max_length)\n",
    "        do_sample=True,\n",
    "        top_k=60,\n",
    "        temperature=0.7 ,\n",
    "    )\n",
    "\n",
    "generated_text = student_tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "generated_answer = generated_text.split(\"Answer: \")[-1].strip()\n",
    "\n",
    "print(\"Prompt:\", prompt)\n",
    "print(\"\\nTrue Answer:\", true_answer)\n",
    "print(\"\\nGenerated Answer:\", generated_answer)\n",
    "print(\"\\nFull Generated Text:\", generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-03T12:18:12.771684Z",
     "iopub.status.busy": "2025-02-03T12:18:12.771375Z",
     "iopub.status.idle": "2025-02-03T12:18:24.993637Z",
     "shell.execute_reply": "2025-02-03T12:18:24.992924Z",
     "shell.execute_reply.started": "2025-02-03T12:18:12.771660Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: <|prompt|> A 7-year-old boy presents with a fever, headache, and severe earache. He also complains of dizziness and a spinning sensation. Examination reveals a red, bulging tympanic membrane. What are the differential diagnoses, and what should be done next?<|completion|>\n",
      "\n",
      "True Answer: This child's symptoms of a red, bulging tympanic membrane with systemic symptoms such as fever and headache, and the additional symptoms of dizziness and a spinning sensation, raise concern for complications of acute otitis media. The differential diagnosis could include labyrinthitis or possibly even mastoiditis. Urgent evaluation, including further imaging studies such as a CT or MRI scan, may be necessary. This child likely requires admission for intravenous antibiotics and possibly surgical intervention if mastoiditis is confirmed.\n",
      "\n",
      "Generated Answer: <|prompt|> A 7-year-old boy presents with a fever, headache, and severe earache. He also complains of dizziness and a spinning sensation. Examination reveals a red, bulging tympanic membrane. What are the differential diagnoses, and what should be done next?<|completion|> A magnetic resonance imaging (MRI) is ordered to assess the tympanic membrane. What is the prognosis for this condition?<|complete|> The tympanic membrane is completely clear. There is no complication. What other tests are done?<|total|> An ultrasound is performed to assess the size of the tympanic membrane. Is the tympanic membrane the type of membrane found in the ear?<|tympanic membrane|> The tympanic membrane is the type of membrane found in the ear. What other tests are done?<|dentition|> A biopsy is performed to confirm the diagnosis. What other tests are done?<|urology|> A CT scan is done to assess the size of the tympanic membrane. What other tests are done?<|surgical procedures|> A biopsy is done to confirm the diagnosis. What other tests are done?<|prognosis|> The tympanic membrane is the type of membrane found in the ear.\n",
      "\n",
      "A. Bacterial ear infections are often associated with earwax accumulation. What is the risk for developing bacterial ear infections?<|alveolar macrophages|> Infection of the earwax with bacteria can lead to bacterial ear infections. What other tests are done?<|prognosis|> The tympanic membrane is the type of membrane found in the ear.\n",
      "\n",
      "A. Bacterial ear infections are often associated with earwax accumulation. What is the risk for developing bacterial ear infections?<|alveolar macrophages|> Infection of the earwax with bacteria can lead to bacterial ear infections. What other tests are done?<|prognosis|> The tympanic membrane is the type of membrane found in the ear.\n",
      "\n",
      "A. Bacterial ear infections are often associated with earwax accumulation. What is the risk for developing bacterial ear infections?<|alveolar macrophages|> Infection of the earwax with bacteria can lead to bacterial ear infections. What other tests are done?<|prognosis|> The tympanic membrane is the type of membrane found in the ear.\n",
      "\n",
      "A. Bacterial ear infections are often associated with earwax accumulation. What is the risk for developing bacterial ear infections?<|alveolar macrophages|> Infection of the earwax with bacteria can lead to bacterial ear infections. What other tests are\n",
      "\n",
      "Full Generated Text: <|prompt|> A 7-year-old boy presents with a fever, headache, and severe earache. He also complains of dizziness and a spinning sensation. Examination reveals a red, bulging tympanic membrane. What are the differential diagnoses, and what should be done next?<|completion|> A magnetic resonance imaging (MRI) is ordered to assess the tympanic membrane. What is the prognosis for this condition?<|complete|> The tympanic membrane is completely clear. There is no complication. What other tests are done?<|total|> An ultrasound is performed to assess the size of the tympanic membrane. Is the tympanic membrane the type of membrane found in the ear?<|tympanic membrane|> The tympanic membrane is the type of membrane found in the ear. What other tests are done?<|dentition|> A biopsy is performed to confirm the diagnosis. What other tests are done?<|urology|> A CT scan is done to assess the size of the tympanic membrane. What other tests are done?<|surgical procedures|> A biopsy is done to confirm the diagnosis. What other tests are done?<|prognosis|> The tympanic membrane is the type of membrane found in the ear.\n",
      "\n",
      "A. Bacterial ear infections are often associated with earwax accumulation. What is the risk for developing bacterial ear infections?<|alveolar macrophages|> Infection of the earwax with bacteria can lead to bacterial ear infections. What other tests are done?<|prognosis|> The tympanic membrane is the type of membrane found in the ear.\n",
      "\n",
      "A. Bacterial ear infections are often associated with earwax accumulation. What is the risk for developing bacterial ear infections?<|alveolar macrophages|> Infection of the earwax with bacteria can lead to bacterial ear infections. What other tests are done?<|prognosis|> The tympanic membrane is the type of membrane found in the ear.\n",
      "\n",
      "A. Bacterial ear infections are often associated with earwax accumulation. What is the risk for developing bacterial ear infections?<|alveolar macrophages|> Infection of the earwax with bacteria can lead to bacterial ear infections. What other tests are done?<|prognosis|> The tympanic membrane is the type of membrane found in the ear.\n",
      "\n",
      "A. Bacterial ear infections are often associated with earwax accumulation. What is the risk for developing bacterial ear infections?<|alveolar macrophages|> Infection of the earwax with bacteria can lead to bacterial ear infections. What other tests are\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch.nn as nn\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "teacher_tokenizer.pad_token = student_tokenizer.eos_token\n",
    "prompt = f\"<|prompt|> {df['Prompt'].iloc[1]}<|completion|>\"\n",
    "true_answer = df[\"Completion\"].iloc[1]\n",
    "\n",
    "teacher_model=teacher_model.to(device)\n",
    "inputs = teacher_tokenizer(prompt, return_tensors=\"pt\", add_special_tokens=True).to(device)\n",
    "\n",
    "\n",
    "output_ids = teacher_model.generate(\n",
    "        inputs.input_ids,\n",
    "        max_new_tokens=512,  # Generate up to 512 new tokens (better than max_length)\n",
    "        do_sample=True,\n",
    "        top_k=60,\n",
    "        temperature=0.62 ,\n",
    "    )\n",
    "\n",
    "generated_text = teacher_tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "generated_answer = generated_text.split(\"Answer: \")[-1].strip()\n",
    "\n",
    "print(\"Prompt:\", prompt)\n",
    "print(\"\\nTrue Answer:\", true_answer)\n",
    "print(\"\\nGenerated Answer:\", generated_answer)\n",
    "print(\"\\nFull Generated Text:\", generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-03T12:44:37.308447Z",
     "iopub.status.busy": "2025-02-03T12:44:37.308137Z",
     "iopub.status.idle": "2025-02-03T12:44:41.937736Z",
     "shell.execute_reply": "2025-02-03T12:44:41.936888Z",
     "shell.execute_reply.started": "2025-02-03T12:44:37.308425Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-5a4d58bbec58>:40: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location='cuda:0')\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: <|prompt|> A 7-year-old boy presents with a fever, headache, and severe earache. He also complains of dizziness and a spinning sensation. Examination reveals a red, bulging tympanic membrane. What are the differential diagnoses, and what should be done next?<|completion|>\n",
      "\n",
      "True Answer: This child's symptoms of a red, bulging tympanic membrane with systemic symptoms such as fever and headache, and the additional symptoms of dizziness and a spinning sensation, raise concern for complications of acute otitis media. The differential diagnosis could include labyrinthitis or possibly even mastoiditis. Urgent evaluation, including further imaging studies such as a CT or MRI scan, may be necessary. This child likely requires admission for intravenous antibiotics and possibly surgical intervention if mastoiditis is confirmed.\n",
      "\n",
      "Generated Answer: <|prompt|> A 7-year-old boy presents with a fever, headache, and severe earache. He also complains of dizziness and a spinning sensation. Examination reveals a red, bulging tympanic membrane. What are the differential diagnoses, and what should be done next?<|completion|> is a common bacterial infection in children. It is treated using antibiotics and a corticosteroid injection. What should be the next step? Aspirin and steroids are contraindications to treatment. What is the recommended course of treatment? The recommended course of therapy is to obtain antibiotics and then apply a corticosteroid, which can be used to stop the infection. What should be done if the tympanoplastic membrane is visible, or if the patient's symptoms worsen? If the tympanoplastic membrane is visible, or the patient's symptoms worsen, what should be done? The primary care provider should rule out other diagnoses, such as pneumonia and sepsis, and prescribe antibiotics. What should be done if the patient has a history of pneumonia? He or she should be evaluated for pneumonia and treatment of the infection. If the patient has a history of pneumonia, the patient should be treated with antibiotics. What is the recommended method of treatment for tympanoplastic membrane infections? The antibiotics are usually given as an intravenous infusion, along with other medications to help fight the infection. What is the recommended treatment for tympanoplastic membrane infections? The antibiotic treatment should be followed by a course of antibiotics that may be used to stop the infection. What is the recommended treatment for tympanoplastic membrane infections? The antibiotic treatment should be followed by a course of antibiotics that may be used to stop the infection. What is the recommended treatment for tympanoplastic membrane infections in patients who have recurrent infections? The antibiotic treatment should be followed by a course of antibiotics that may be used to stop the infection. What is the recommended treatment for tympanoplastic membrane infections in patients who have recurrent infections? The antibiotic treatment should be followed by a course of antibiotics that may be used to stop the infection. What is the recommended treatment for tympanoplastic membrane infections in patients who have recurrent infections? The antibiotic treatment should be followed by a course of antibiotics that may be used to stop the infection. What is the recommended treatment for tympanoplastic membrane infections in patients who have recurrent infections? The antibiotic treatment should be followed by a course of antibiotics that may be used to stop the infection. What is the recommended treatment for tympanoplastic membrane infections in patients who have recurrent infections? The antibiotic treatment should be followed by a course of antibiotics that may be used to stop the infection. What is the recommended treatment for tympanoplastic membrane infections in patients who have recurrent infections\n",
      "\n",
      "Full Generated Text: <|prompt|> A 7-year-old boy presents with a fever, headache, and severe earache. He also complains of dizziness and a spinning sensation. Examination reveals a red, bulging tympanic membrane. What are the differential diagnoses, and what should be done next?<|completion|> is a common bacterial infection in children. It is treated using antibiotics and a corticosteroid injection. What should be the next step? Aspirin and steroids are contraindications to treatment. What is the recommended course of treatment? The recommended course of therapy is to obtain antibiotics and then apply a corticosteroid, which can be used to stop the infection. What should be done if the tympanoplastic membrane is visible, or if the patient's symptoms worsen? If the tympanoplastic membrane is visible, or the patient's symptoms worsen, what should be done? The primary care provider should rule out other diagnoses, such as pneumonia and sepsis, and prescribe antibiotics. What should be done if the patient has a history of pneumonia? He or she should be evaluated for pneumonia and treatment of the infection. If the patient has a history of pneumonia, the patient should be treated with antibiotics. What is the recommended method of treatment for tympanoplastic membrane infections? The antibiotics are usually given as an intravenous infusion, along with other medications to help fight the infection. What is the recommended treatment for tympanoplastic membrane infections? The antibiotic treatment should be followed by a course of antibiotics that may be used to stop the infection. What is the recommended treatment for tympanoplastic membrane infections? The antibiotic treatment should be followed by a course of antibiotics that may be used to stop the infection. What is the recommended treatment for tympanoplastic membrane infections in patients who have recurrent infections? The antibiotic treatment should be followed by a course of antibiotics that may be used to stop the infection. What is the recommended treatment for tympanoplastic membrane infections in patients who have recurrent infections? The antibiotic treatment should be followed by a course of antibiotics that may be used to stop the infection. What is the recommended treatment for tympanoplastic membrane infections in patients who have recurrent infections? The antibiotic treatment should be followed by a course of antibiotics that may be used to stop the infection. What is the recommended treatment for tympanoplastic membrane infections in patients who have recurrent infections? The antibiotic treatment should be followed by a course of antibiotics that may be used to stop the infection. What is the recommended treatment for tympanoplastic membrane infections in patients who have recurrent infections? The antibiotic treatment should be followed by a course of antibiotics that may be used to stop the infection. What is the recommended treatment for tympanoplastic membrane infections in patients who have recurrent infections\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch.nn as nn\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model = model.to(device)\n",
    "student_tokenizer.pad_token = student_tokenizer.eos_token\n",
    "prompt = f\"<|prompt|> {df['Prompt'].iloc[1]}<|completion|>\"\n",
    "\n",
    "true_answer = df[\"Completion\"].iloc[1]\n",
    "\n",
    "inputs = student_tokenizer(prompt, return_tensors=\"pt\", add_special_tokens=True).to(device)\n",
    "\n",
    "model_path=\"/kaggle/input/gpt2-d/pytorch/default/1/best_model(9).pth\"\n",
    "\n",
    "checkpoint = torch.load(model_path, map_location='cuda:0')\n",
    "\n",
    "# Load the model weights\n",
    "\n",
    "from collections import OrderedDict\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in checkpoint.items():\n",
    "    name = k[7:]  # remove 'module.' from key names\n",
    "    new_state_dict[name] = v\n",
    "\n",
    "student_model.load_state_dict(new_state_dict)\n",
    "student_model.eval()\n",
    "\n",
    "student_model.to(device)\n",
    "with torch.no_grad():\n",
    "    output_ids = student_model.generate(\n",
    "        inputs.input_ids,\n",
    "        max_new_tokens=512,  \n",
    "        do_sample=True,\n",
    "        top_k=60,\n",
    "        temperature=0.65 ,\n",
    "    )\n",
    "\n",
    "generated_text = student_tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "generated_answer = generated_text.split(\"Answer: \")[-1].strip()\n",
    "\n",
    "print(\"Prompt:\", prompt)\n",
    "print(\"\\nTrue Answer:\", true_answer)\n",
    "print(\"\\nGenerated Answer:\", generated_answer)\n",
    "print(\"\\nFull Generated Text:\", generated_text)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "isSourceIdPinned": true,
     "modelId": 230333,
     "modelInstanceId": 208646,
     "sourceId": 244233,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 234450,
     "modelInstanceId": 212808,
     "sourceId": 248966,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30840,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
